### ğŸ“Œ **What is the Correlation Coefficient?**

The **correlation coefficient** is a **statistical measure** that tells you how strongly two variables are related â€” and in which **direction**.

---

### âœ… **Key Points**

| Feature    | Description                                                                     |
| ---------- | ------------------------------------------------------------------------------- |
| Symbol     | Usually denoted as **r** (for Pearson), **Ï** (Spearman), or **Ï„** (Kendall)    |
| Range      | From **-1 to +1**                                                               |
| Purpose    | To measure **direction** and **strength** of the relationship between variables |
| Common Use | Understanding patterns, trends, and dependencies between data features          |

---

### ğŸ“ˆ **Values and Their Meaning**

| Correlation Coefficient (r) | Interpretation                   |
| --------------------------- | -------------------------------- |
| `+1.0`                      | Perfect **positive** correlation |
| `+0.7 to +0.9`              | Strong positive correlation      |
| `+0.4 to +0.7`              | Moderate positive correlation    |
| `0`                         | No correlation                   |
| `-0.4 to -0.7`              | Moderate negative correlation    |
| `-0.7 to -0.9`              | Strong negative correlation      |
| `-1.0`                      | Perfect **negative** correlation |

---

### ğŸ§® **Formula (for Pearson Correlation)**

$$
r = \frac{\sum (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum (x_i - \bar{x})^2} \cdot \sqrt{\sum (y_i - \bar{y})^2}}
$$

Where:

* $x_i, y_i$ are data points
* $\bar{x}, \bar{y}$ are means of x and y

---

### ğŸ§  **Interpretation Example**

Letâ€™s say:

* Height increases â†’ Weight increases
  Then the **correlation coefficient** between height and weight might be **+0.85**, indicating a **strong positive** relationship.

---

### âš ï¸ **Important Notes**

1. **Correlation â‰  Causation**
   Just because two variables are correlated does not mean one causes the other.

2. **Sensitive to Outliers**
   Especially for **Pearson's r**, one extreme value can change the result significantly.

3. **Linear Only (Pearson)**
   It only measures **linear** relationships unless you use Spearman or Kendall for ranked/monotonic ones.

---
## Various methods of measuring correlation
---
## ğŸ”¢ **1. Pearson Correlation Coefficient (r)**

### âœ… Use When:

* Both variables are **continuous**.
* The relationship is **linear**.
* Data is **normally distributed**.

### ğŸ“ Formula:

$$
r = \frac{\text{Cov}(X, Y)}{\sigma_X \cdot \sigma_Y}
$$

### ğŸŸ¢ Output:

* Values range from **-1 to +1**
* Measures **linear** relationship strength and direction.

### ğŸ”§ Python:

```python
from scipy.stats import pearsonr
r, p = pearsonr(x, y)
```

---

## ğŸ”¢ **2. Spearmanâ€™s Rank Correlation Coefficient (Ï or `spearman`)**

### âœ… Use When:

* Data is **ordinal** or **not normally distributed**.
* Relationship is **monotonic** (consistently increasing or decreasing).

### ğŸ“ Method:

* Converts data to **ranks** and computes Pearson correlation on ranks.

### ğŸ”§ Python:

```python
from scipy.stats import spearmanr
rho, p = spearmanr(x, y)
```

---

## ğŸ”¢ **3. Kendallâ€™s Tau (Ï„)**

### âœ… Use When:

* **Small sample size**
* **Non-parametric**, works well with **ties** and **ordinal data**.

### ğŸ“ Idea:

* Measures number of **concordant** vs. **discordant** pairs.

### ğŸ”§ Python:

```python
from scipy.stats import kendalltau
tau, p = kendalltau(x, y)
```

---

## ğŸ”¢ **4. Point-Biserial Correlation**

### âœ… Use When:

* One variable is **binary** (0 or 1)
* The other is **continuous**

### ğŸ”§ Python:

```python
from scipy.stats import pointbiserialr
r, p = pointbiserialr(binary_var, continuous_var)
```

---

## ğŸ”¢ **5. Phi Coefficient (Ï†)**

### âœ… Use When:

* Both variables are **binary**

### ğŸ”§ Python:

```python
from scipy.stats import chi2_contingency
from sklearn.metrics import matthews_corrcoef
phi = matthews_corrcoef(binary1, binary2)
```

---

## ğŸ”¢ **6. CramÃ©râ€™s V**

### âœ… Use When:

* Both variables are **categorical (nominal)** with more than two categories.

### ğŸ”§ Python:

```python
import pandas as pd
import numpy as np
from scipy.stats import chi2_contingency

def cramers_v(x, y):
    confusion_matrix = pd.crosstab(x, y)
    chi2 = chi2_contingency(confusion_matrix)[0]
    n = confusion_matrix.sum().sum()
    phi2 = chi2 / n
    r, k = confusion_matrix.shape
    return np.sqrt(phi2 / min(k - 1, r - 1))
```

---

## ğŸ§  **Summary Table**

| Method              | Data Type                 | Relationship Type | Suitable For  |
| ------------------- | ------------------------- | ----------------- | ------------- |
| **Pearson**         | Continuous                | Linear            | Normal data   |
| **Spearman**        | Ordinal / Continuous      | Monotonic         | Ranked data   |
| **Kendallâ€™s Tau**   | Ordinal                   | Monotonic         | Small samples |
| **Point-Biserial**  | Binary + Continuous       | Linear            | Binary flag   |
| **Phi Coefficient** | Binary + Binary           | Association       | Contingency   |
| **CramÃ©râ€™s V**      | Categorical + Categorical | Association       | Contingency   |

---

